{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–ò–ê–ì–ù–û–°–¢–ò–†–û–í–ê–ù–ò–ï –°–ö–õ–û–ù–ù–û–°–¢–ò –ê–í–¢–û–†–ê –ü–ò–°–¨–ú–ï–ù–ù–û–ì–û –¢–ï–ö–°–¢–ê –ö –ê–£–¢–û–ê–ì–†–ï–°–°–ò–í–ù–û–ú–£ –ü–û–í–ï–î–ï–ù–ò–Æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"–°—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏–∏ÃÜ, –∑–∞—á–µ—Ç–Ω—É—é –∫–Ω–∏–∂–∫—É –∏ –í–ö–† –æ–±–º–µ–Ω—è–ª–∞ –Ω–∞ –∫—Ä–∞—Å–∏–≤–µ–Ω—å–∫–∏–∏ÃÜ –¥–∏–ø–ª–æ–ºüîπ\n",
    "–†–∞–Ω—å—à–µ —è –∫–∞–∫-—Ç–æ –Ω–µ –º–æ–≥–ª–∞ —Ç–æ—á–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: ¬´–ó–∞—á–µ–º —Ç—Ä–∞—Ç–∏—Ç—å 4 –≥–æ–¥–∞ –Ω–∞ –∫–æ—Ä–æ—á–∫—É –æ –≤—ã—Å—à–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∏ –Ω–∞ –∑–Ω–∞–Ω–∏—è, 80% –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞?¬ª. –ü—Ä–æ—Å—Ç–æ –Ω–∞–¥–æ –∏ –≤—Å–µÃà.\n",
    "–ù–æ —Å–µ–∏ÃÜ—á–∞—Å —Å–ø—É—Å—Ç—è 8 —Å–µ–º–µ—Å—Ç—Ä–æ–≤, —Å–æ—Ç–Ω–∏ –ø–∞—Ä –∏ –¥–µ—Å—è—Ç–∫–∏ —Å–¥–∞–Ω–Ω—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤, —è —Ç–æ—á–Ω–æ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å. –í –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç —Å—Ç–æ–∏—Ç –∏–¥—Ç–∏ –∏–∑-–∑–∞ –ª—é–¥–µ–∏ÃÜ. –õ—é–¥–µ–∏ÃÜ, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –æ–∫—Ä—É–∂–∞—Ç—å —Ç–µ–±—è –≤—Å–µ —ç—Ç–æ –≤—Ä–µ–º—è, –Ω–∞–ø—Ä–∞–≤–ª—è—Ç—å, –º–µ–Ω—è—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å. –ó–¥–µ—Å—å —è –Ω–∞—à–ª–∞ —Å–≤–æ–∏—Ö —Ä–æ–¥–Ω—ã—Ö –¥–µ–≤–æ—á–µ–∫, –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∞—Å—å —Å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º–∏ –ª—é–¥—å–º–∏ –∏ —É–∑–Ω–∞–ª–∞ –º–Ω–æ–≥–æ –Ω–æ–≤–æ–≥–æ. –û—á–µ–Ω—å –≥—Ä—É—Å—Ç–Ω–æ, —á—Ç–æ –±–æ–ª—å—à–µ –Ω–µ –ø—Ä–æ–≥—É–ª—è–µ–º –ø–∞—Ä—ã, –Ω–µ –æ–ø–æ–∑–¥–∞–µ–º –Ω–∞ –ª–µ–∫—Ü–∏–∏, –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞–µ–º –∞—É–¥–∏—Ç–æ—Ä–∏–∏, –Ω–µ –∑–∞–±–ª—É–¥–∏–º—Å—è –≤ –∞–∫–∞–¥–µ–º–∏–∏ –∏ –Ω–µ –±—É–¥–µ–º –≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —ç–∫–∑–∞–º–µ–Ω—É –≤ –ú–∞–∫–¥–æ–Ω–∞–ª—å–¥—Å–µ –Ω–∞ –≤—Ç–æ—Ä–æ–º —ç—Ç–∞–∂–µ‚ù§Ô∏è\n",
    "–Ø –ø—Ä–æ—â–∞—é—Å—å —Å –±–µ–∑—É–º–Ω–æ –≤–∞–∂–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º –º–æ–µ–∏ÃÜ –∂–∏–∑–Ω–∏, –≤–∞–∂–Ω—ã–º –Ω–µ –∏–∑-–∑–∞ –∫–æ—Ä–æ—á–∫–∏ –≤ –º–æ–∏—Ö —Ä—É–∫–∞—Ö (—Ö–æ—Ç—è —ç—Ç–æ —Ç–æ–∂–µ –∏–º–µ–µ—Ç –±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ), –∞ –∏–∑-–∑–∞ –ª—é–±–∏–º—ã—Ö –∏ –¥–æ—Ä–æ–≥–∏—Ö –º–Ω–µ —á–µ–ª–æ–≤–µ—á–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–≤—Å–µ–≥–¥–∞ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –≤ –º–æ–µ–º —Å–µ—Ä–¥—Ü–µ. –í—Å–µ—Ö –ª—é–±–ª—é‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–¥–µ–∫—Å—ã —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤, —Ç.–µ. –º–µ—Ä–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è —Ç–µ–∫—Å—Ç–∞ —á–∏—Ç–∞—Ç–µ–ª–µ–º.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from nltk import tokenize\n",
    "import re\n",
    "import nltk\n",
    "import pyphen\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    \"\"\"\n",
    "        Returns a list of all words found in the text.\n",
    "    \"\"\"\n",
    "    word_tokenizer = tokenize.TreebankWordTokenizer()\n",
    "    words = [w.strip().lower() for w in word_tokenizer.tokenize(text) if w.strip()]\n",
    "\n",
    "    # Remove punctuation from words:\n",
    "    # Ex.:  <<This is the final.>>  becomes\n",
    "    # ['<','<', 'This', 'is', 'the', 'final', '.', '>', '>'] -> ['This', 'is', 'the', 'final']\n",
    "    words = [re.sub(\"\\W\", '', word) for word in words]\n",
    "    words = [word for word in words if word]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    \"\"\"\n",
    "         Returns a list of all sentences found in the text.\n",
    "    \"\"\"\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    sentences_only_chars = []\n",
    "    # Remove sentences containing only punctuation:\n",
    "    for sentence in sentences:\n",
    "        if re.sub(\"\\W\", \"\", sentence):\n",
    "            sentences_only_chars.append(sentence)\n",
    "    return sentences_only_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sentences(text)\n",
    "words = get_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_sentences = len(sentences) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "number_words = len(words) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_syllables(words):\n",
    "        dic = pyphen.Pyphen(lang='ru')\n",
    "\n",
    "        syllables = 0\n",
    "        words_3_syllables_more = 0\n",
    "\n",
    "        for word in words:\n",
    "            syl = len(dic.inserted(word).split(\"-\"))\n",
    "            syllables += syl\n",
    "            if syl >= 3:\n",
    "                words_3_syllables_more += 1\n",
    "        return syllables, words_3_syllables_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_syllables - –∫–æ–ª–∏—á—Å—Ç–≤–æ —Å–ª–æ–≥–æ–≤\n",
    "# number_polysyllable_words - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–∂–Ω—ã—Ö —Å–ª–æ–≤ \n",
    "number_syllables, number_polysyllable_words = get_number_syllables(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–¥–µ–∫—Å —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –§–ª–µ—à–∞\n",
    "flesh = 206.835 - 1.3 * (number_words / number_sentences) - 60.1 * (number_syllables / number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  –ò–Ω–¥–µ–∫—Å –ì–∞–Ω–Ω–∏–Ω–≥–∞ (–∏–ª–∏ –§–æ–≥-–∏–Ω–¥–µ–∫—Å, Fog Index).\n",
    "fog_index= 0.4 * (0.78*((number_words / number_sentences)) + 100 * (number_polysyllable_words / number_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "avrg_len_sentence = len(words)/len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for sentence in sentences:\n",
    "    length.append(len(get_words(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_word_in_sentence = np.average(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_word_in_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–¥–µ–∫—Å –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ç–µ–∫—Å—Ç–∞ (TTR token type ration)\n",
    "document= re.sub(r'[^\\w]', ' ', text)\n",
    "document=document.lower()\n",
    "tokens=nltk.word_tokenize(document)\n",
    "types=nltk.Counter(tokens)\n",
    "TTR= (len(types)/len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75625"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–ª—è –ø—Ä–µ–ª–æ–≥–æ–≤ (PREP) –≤ —Ç–µ–∫—Å—Ç–µ \n",
    "document= re.sub(r'[^\\w]', ' ', text)\n",
    "tokens=nltk.word_tokenize(document)\n",
    "\n",
    "count_prep = 0\n",
    "for word in tokens:\n",
    "    p = morph.parse(word)[0]\n",
    "    if p.tag.POS == 'PREP':\n",
    "        count_prep+=1\n",
    "    \n",
    "percentage_unions_in_the_text = count_prep/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = average_word_in_sentence\n",
    "x2 = TTR\n",
    "x3 = percentage_unions_in_the_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.708737499999999\n"
     ]
    }
   ],
   "source": [
    "# –ë–∞–ª–ª—ã –ø–æ —à–∫–∞–ª–µ ¬´–°–ø–æ–Ω—Ç–∞–Ω–Ω–∞—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç—å¬ª\n",
    "\n",
    "spontaneous_aggression = 22.996 + (0.169*x1) - (21.910*x2)-(39.948*x3)\n",
    "print(spontaneous_aggression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-985deff74a8f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-985deff74a8f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class AutoargressionAnalysis()\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"\"\"–°—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏–∏ÃÜ, –∑–∞—á–µ—Ç–Ω—É—é –∫–Ω–∏–∂–∫—É –∏ –í–ö–† –æ–±–º–µ–Ω—è–ª–∞ –Ω–∞ –∫—Ä–∞—Å–∏–≤–µ–Ω—å–∫–∏–∏ÃÜ –¥–∏–ø–ª–æ–ºüîπ\n",
    "–†–∞–Ω—å—à–µ —è –∫–∞–∫-—Ç–æ –Ω–µ –º–æ–≥–ª–∞ —Ç–æ—á–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: ¬´–ó–∞—á–µ–º —Ç—Ä–∞—Ç–∏—Ç—å 4 –≥–æ–¥–∞ –Ω–∞ –∫–æ—Ä–æ—á–∫—É –æ –≤—ã—Å—à–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∏ –Ω–∞ –∑–Ω–∞–Ω–∏—è, 80% –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞?¬ª. –ü—Ä–æ—Å—Ç–æ –Ω–∞–¥–æ –∏ –≤—Å–µÃà.\n",
    "–ù–æ —Å–µ–∏ÃÜ—á–∞—Å —Å–ø—É—Å—Ç—è 8 —Å–µ–º–µ—Å—Ç—Ä–æ–≤, —Å–æ—Ç–Ω–∏ –ø–∞—Ä –∏ –¥–µ—Å—è—Ç–∫–∏ —Å–¥–∞–Ω–Ω—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤, —è —Ç–æ—á–Ω–æ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å. –í –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç —Å—Ç–æ–∏—Ç –∏–¥—Ç–∏ –∏–∑-–∑–∞ –ª—é–¥–µ–∏ÃÜ. –õ—é–¥–µ–∏ÃÜ, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –æ–∫—Ä—É–∂–∞—Ç—å —Ç–µ–±—è –≤—Å–µ —ç—Ç–æ –≤—Ä–µ–º—è, –Ω–∞–ø—Ä–∞–≤–ª—è—Ç—å, –º–µ–Ω—è—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å. –ó–¥–µ—Å—å —è –Ω–∞—à–ª–∞ —Å–≤–æ–∏—Ö —Ä–æ–¥–Ω—ã—Ö –¥–µ–≤–æ—á–µ–∫, –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∞—Å—å —Å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º–∏ –ª—é–¥—å–º–∏ –∏ —É–∑–Ω–∞–ª–∞ –º–Ω–æ–≥–æ –Ω–æ–≤–æ–≥–æ. –û—á–µ–Ω—å –≥—Ä—É—Å—Ç–Ω–æ, —á—Ç–æ –±–æ–ª—å—à–µ –Ω–µ –ø—Ä–æ–≥—É–ª—è–µ–º –ø–∞—Ä—ã, –Ω–µ –æ–ø–æ–∑–¥–∞–µ–º –Ω–∞ –ª–µ–∫—Ü–∏–∏, –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞–µ–º –∞—É–¥–∏—Ç–æ—Ä–∏–∏, –Ω–µ –∑–∞–±–ª—É–¥–∏–º—Å—è –≤ –∞–∫–∞–¥–µ–º–∏–∏ –∏ –Ω–µ –±—É–¥–µ–º –≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —ç–∫–∑–∞–º–µ–Ω—É –≤ –ú–∞–∫–¥–æ–Ω–∞–ª—å–¥—Å–µ –Ω–∞ –≤—Ç–æ—Ä–æ–º —ç—Ç–∞–∂–µ‚ù§Ô∏è\n",
    "–Ø –ø—Ä–æ—â–∞—é—Å—å —Å –±–µ–∑—É–º–Ω–æ –≤–∞–∂–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º –º–æ–µ–∏ÃÜ –∂–∏–∑–Ω–∏, –≤–∞–∂–Ω—ã–º –Ω–µ –∏–∑-–∑–∞ –∫–æ—Ä–æ—á–∫–∏ –≤ –º–æ–∏—Ö —Ä—É–∫–∞—Ö (—Ö–æ—Ç—è —ç—Ç–æ —Ç–æ–∂–µ –∏–º–µ–µ—Ç –±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ), –∞ –∏–∑-–∑–∞ –ª—é–±–∏–º—ã—Ö –∏ –¥–æ—Ä–æ–≥–∏—Ö –º–Ω–µ —á–µ–ª–æ–≤–µ—á–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–≤—Å–µ–≥–¥–∞ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –≤ –º–æ–µ–º —Å–µ—Ä–¥—Ü–µ. –í—Å–µ—Ö –ª—é–±–ª—é‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è \"\"\",\n",
    "        \"–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: –ª–∞—Ç—Ç–µ —Å –∫–æ–∫–æ—Å–æ–≤—ã–º —Å–∏—Ä–æ–ø–æ–º, –ª–µ—Ç–æ –∏ —à–æ–ø–ø–∏–Ω–≥‚ú®üôÉ –°–∫—É—á–∞–ª–∞ –ø–æ —ç—Ç–æ–º—Éüíî\",\n",
    "        \"–î–æ–±–∞–≤–ª—é –∫—Ä–∞—Å–æ–∫ –≤ –≤–∞—à—É –∏–Ω—Å—Ç–∞–≥—Ä–∞–º–º –ª–µ–Ω—Ç—É‚ú®\"\n",
    "        \"–î–æ—Ä–æ–≥–∏–µ –º–æ–∏, —Å–ø–∞—Å–∏–±–æ, —á—Ç–æ –±—ã–ª–∏ —Å –Ω–∞–º–∏ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å‚ù§Ô∏è –ò —Å–ø–∞—Å–∏–±–æ —Ç–µ–º, –∫—Ç–æ –ø–æ–∑–¥—Ä–∞–≤–∏–ª, –ø–æ–∑–≤–æ–Ω–∏–ª, –Ω–∞–ø–∏—Å–∞–ª‚ù§Ô∏è –≠—Ç–æ –±—ã–ª –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –¥–µ–Ω—å, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –≤—Å–µ –≤–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –∏ –Ω–∞ —Ç–æ, —á—Ç–æ –Ω–∞—Å —Ä–∞—Å–ø–∏—Å—ã–≤–∞–ª —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç–æ—Ä –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –º–∞—Å–∫–µüòπ –¢–∞–∫–æ–µ —Ç–æ—á–Ω–æ –¥–æ –∫–æ–Ω—Ü–∞ –∂–∏–∑–Ω–∏ –Ω–µ –∑–∞–±—É–¥–µ—Ç—Å—èüòπ\"\n",
    "        \"–í —ç—Ç–æ–º –º–∞–µ —è —É—Ç–æ–Ω—É –≤ —Ü–≤–µ—Ç–∞—Öüå∫\",\n",
    "        \"–ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, –µ—Å–ª–∏ –ø—Ä–æ–¥–ª—è—Ç –∫–∞—Ä–∞–Ω—Ç–∏–Ω –Ω–∞ –ª–µ—Ç–æ, —Ç–æ –ø–æ—Å–ª–µ –ì–û–°–æ–≤ –∏ –í–ö–†, –º–æ–∏–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –∑–∞–Ω—è—Ç–∏–µ–º —Å—Ç–∞–Ω–µ—Ç –æ—Ç—Ä–∞—â–∏–≤–∞–Ω–∏–µ –≤–æ–ª–æ—Å –∏ NetflixüòÇ –ù–æ –ø–æ–∫–∞ –¥–µ—Ä–∂—É—Å—å, –∏ –∫–∞–∫ –º–Ω–æ–≥–∏–µ, —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—Å—å. –Ø —É–º–Ω–∏—á–∫–∞üôÉ #—Å–∞–º—Å–µ–±—è–Ω–µ–ø–æ—Ö–≤–∞–ª–∏—à—å–Ω–∏–∫—Ç–æ–Ω–µ–ø–æ—Ö–≤–∞–ª–∏—Ç\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.statistics import autoaression\n",
    "spontaneous_aggression = []\n",
    "depression = []\n",
    "balance = []\n",
    "emotional_lability = []\n",
    "for tex in text:\n",
    "    auto = autoaression.AutoaggressionAnalysis(tex)\n",
    "    spontaneous_aggression.append(auto.spontaneous_aggression())\n",
    "    depression.append(auto.depression())\n",
    "    balance.append(auto.balance())\n",
    "    emotional_lability.append(auto.emotional_lability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.084783313041126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(emotional_lability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.74141139745671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.193976488095239"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.884347470238094"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(spontaneous_aggression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
